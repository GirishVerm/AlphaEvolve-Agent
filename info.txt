1. give a task/outcome; 
   optional set of stubs of starting tools; 
   optional initial spec to test performance against; 
   an optional initial prompt;

2. agent comes up with key questions, considerations, and edge cases for task - 
   asks human to add their input on these

3. agent comes up with questions, considerations, edge cases and, 
   recommendations for improvements to initial tools if tools already provided 
   OTHERWISE first comes up with an initial ideal toolset, 
   asks for human validation then does the same improvement.

4. agent comes up with questions, considerations, edge cases and, 
   recommendations for improvements to initial spec if spec already provided 
   OTHERWISE first comes up with a spec, 
   asks for human validation then does the same improvement. 
   Builds out a "hard" eval set of the task with deliberate edge-cases/ambiguities as part of it

5. agent deep thinks to come up with various independent "edits" to prompt + tools + memory 
   and uses evolutionary algorithms to propagate the changes that work best against the spec

build this